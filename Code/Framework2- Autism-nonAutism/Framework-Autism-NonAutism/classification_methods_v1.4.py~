# *******this version is for Binary classificstion of Autism vs Non_Autism******
from numpy import genfromtxt
from sklearn import preprocessing
import numpy as np 
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn import grid_search
from sklearn import datasets, linear_model, cross_validation, grid_search
import numpy as np
from numpy import genfromtxt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn import grid_search
from sklearn.preprocessing import Imputer
from sklearn.cross_validation import train_test_split
#from preprocessing_data import preprocess
import csv
import  scipy.stats as stats
from sklearn.cross_validation import cross_val_score
np.set_printoptions(precision=4)
cm_list=[] 
classifier_list=[]
plt.close('all')

# http://stackoverflow.com/questions/5957470/matlab-style-find-function-in-python
def indices(a, func):# ~ Find in matlab  
    return [i for (i, val) in enumerate(a) if func(val)]

def unique(a):# removing duplicate rows
    order = np.lexsort(a.T)
    a = a[order]
    diff = np.diff(a, axis=0)
    ui = np.ones(len(a), 'bool')
    ui[1:] = (diff != 0).any(axis=1) 
    return a[ui]
def cross_val_eval(predicted , ytrain):
        Error_rate = np.absolute(np.subtract(ytrain, predicted))
        result= np.column_stack ((ytrain,predicted))
        Acu_rate=np.column_stack ((result,Error_rate))
        temp_indx=indices(Acu_rate [:,Acu_rate.shape[1]-1], lambda x: x == 2)
        Acu_rate[temp_indx] = 0 
        #np.savetxt("yetest_ypred_multiclass.csv", Acu_rate, delimiter=",") 
        Accu =1-( np.sum(Acu_rate[:,Acu_rate.shape[1]-1])/Acu_rate.shape[0])
        return Accu 

def evaluate(clf, xtrain, xtest, ytrain, ytest, classifier_name):
        ypredtrain = clf.predict(xtrain)
        ypred = clf.predict(xtest)
        ypredSoft= clf.predict_proba(xtest)   
        ypredSoft = ypredSoft[:, 1];         
        print 'Confusion Matrix:' 
        cm = confusion_matrix(ytest, ypred)
        #print cm
        Error_rate = np.absolute(np.subtract(ytest, ypred))
        result= np.column_stack ((ytest,ypred))
        Acu_rate=np.column_stack ((result,Error_rate))
        temp_indx=indices(Acu_rate [:,Acu_rate.shape[1]-1], lambda x: x == 2)
        Acu_rate[temp_indx] = 0 
        #np.savetxt("yetest_ypred_multiclass.csv", Acu_rate, delimiter=",") 
        Accu =1-( np.sum(Acu_rate[:,Acu_rate.shape[1]-1])/Acu_rate.shape[0])
        
        TN = cm[0][0]
        FP = cm[0][1]
        FN = cm[1][0]
        TP = cm[1][1]
        #print 'Precision = ', metrics.precision_score(ytest, ypred)
        SPC= 1.0*TN/(TN+FP) 
        print 'Specificity = ' ,np.around(SPC ,decimals=3)
        print 'Sensitivity = ', np.around(metrics.recall_score(ytest, ypred),decimals=3) # Same as Recall 
        #print 'F1 Score = ', f1_score(ytest, ypred)
        fpr, tpr, thresholds = metrics.roc_curve(ytest, ypredSoft)
        roc_auc = metrics.auc(fpr, tpr)
        print 'AUC = ', np.around(metrics.auc(fpr, tpr),decimals=3)
        print 'Accuracy on train data:%f'% np.around(metrics.accuracy_score(ytrain,ypredtrain),decimals=3)
        print 'Accuracy on test data:%f'% np.around(metrics.accuracy_score(ytest,ypred),decimals=3)
        
        #-----------Plotting the ROC Curve
        plt.plot(fpr, tpr, label=classifier_name + '(area = %0.2f)' % roc_auc)
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver operating characteristic example')
        plt.legend(loc="lower right")
        #plot_cm(cm,classifier_name)
        cm_list.append(cm)
        classifier_list.append(classifier_name)
        return Accu

def train_test_split(x_train, y_train,split_ratio):
# Splitting data to train and test #########
# "give Xtrain and y_train and test split size as input 
# return seperate train and test splits for both X and Y "
    label_1 = indices(y_train , lambda x: x == 1)
    label_0 = indices(y_train , lambda x: x == 0)
    print len(label_1)
    print len(label_0)
    # ------ extrating test data split 
    test_split_ratio= split_ratio#0.2 # in put of the function 
    test_range=int(len(label_1)*test_split_ratio)
    print test_range  
    test_range = int(test_range)
    #print np.round(len(label_1)*test_split_ratio)
    print test_range
    test_indx_1=label_1[0:test_range]
    test_indx_0=label_0[0:test_range]
    test_split_x=np.concatenate((x_train[test_indx_1,:],x_train[test_indx_0,:]),axis=0)
    test_split_y=np.concatenate((y_train[test_indx_1],y_train[test_indx_0]),axis=0)
    # ------ extrating train data split 
    train_indx_1=label_1[test_range:]
    train_indx_0=label_0[test_range:]
    train_split_x=np.concatenate((x_train[train_indx_1,:],x_train[train_indx_0,:]),axis=0)
    train_split_y=np.concatenate((y_train[train_indx_1],y_train[train_indx_0]),axis=0)
    
    print ('Inside Function')
    test = np.column_stack((test_split_x,test_split_y))
    train=np.column_stack((train_split_x, train_split_y))
    np.random.shuffle(train)
    np.random.shuffle(test)
    train_split_y = train[:,train.shape[1]-1]
    train_split_x = train[:,:train.shape[1]-1]
    print train_split_x.shape
    test_split_y = test[:,test.shape[1]-1]
    test_split_x = test[:,:test.shape[1]-1]
    print test_split_x.shape
    return test_split_x, test_split_y , train_split_x , train_split_y
#train = df[msk]
#test = df[~msk]

############### Reading the Data ###############
#--------------Importing the files
#Autism _T_group1to5_ROI_ver2
train = genfromtxt('Autism_T_Autism_vs_nonAutism.csv', delimiter=',') # no activation 
train = train[1: , 2:]
print train.shape
train= unique(train)
print train.shape
np.random.shuffle(train)
print train.shape
#***********************************************
#********** Indices_Scaled _Data_Top 50  *******
#***********************************************
# d_indices 
# 255,17,288,206,56,97,136,191,249,298,9,146,198,225,272,119,25,376,248,96,149,354,238,70,63,145,8,252,224,16,168,0,335,185,352,207,	273,127,148,24,79,159,306,280,7,109,190,129,264,153
# q_indices :
#255,17,119,206,97,249,354,198,56,146,225,185,0,136,25,298,71,248,168,128,16,7,247,96,127,272,149,246,118,129,191,70,252,109,199,	24,121,344,250,57,135,207,142,148,120,238,293,158,153,143
#***********************************************
#********** Indices_Not Scaled _Data_Top 50 ****
#***********************************************
# d_indices :
#199,335,281,229,355,328,376,174,259,293,272,206,334,153,321,280,202,333,207,354,319,227,365,322,179,300,273,329,211,323,366,146,	306,195,275,180,337,357,178,302,235,367,209,349,111,248,292,144,307,132
# q_indices :
# 199,119,198,121,249,143,272,86,70,135,14,133,0,252,255,142,222,225,185,214,10,128,246,123,196,71,216,5,215,250,56,204,158,7,277,	344,140,146,170,206,248,292,247,63,251,113,97,217,21,68

# getting equal number of samples from each label 
inds_1 = indices(train [:,train.shape[1]-1], lambda x: x == 1)
inds_0 = indices(train [:,train.shape[1]-1], lambda x: x == 0)
print len(inds_0)
print len(inds_1)
D=np.minimum(len(inds_1),len(inds_0))
'''
indx=np.concatenate((inds_1[0:D],inds_0[0:D]),axis=0)
train= train[indx,:] # extracting a subset with equal number of samples in each class 
np.random.shuffle(train)
'''
y_train = train[:,train.shape[1]-1]
x_train = train[:,:train.shape[1]-1]

# imputing the missing values with feature mean 
import  scipy.stats as stats
col_mean = stats.nanmean(x_train,axis=0)
inds = np.where(np.isnan(x_train))
print inds
x_train[inds]=np.take(col_mean,inds[1])
preprocessed_data= np.column_stack((x_train,y_train))
#TOP50 = 123,317,134,326,79,191,152,61,271,298,6,378,29,253,373,151,63,69,273,107,224,332,279,144,75,259,16,70,309,4,214,	314,22,72,7,376,153,64,381,146,281,1,251,112,308,143,353,10,363,170

#============ selected features by mRMR-Top50  =====================
#x_train = train[:,[123,317,134,326,79,191,152,61,271,298,6,378,29,253,373,151,63,69,273,107]]
############## Standarize the features
#scaler=preprocessing.StandardScaler().fit(x_train) ************************

#x_train= scaler.transform (x_train)   ************
#x_train= genfromtxt('Xtrain.csv', delimiter=',') *************** transformed features by matlab 
#np.savetxt("Autim_nonAutism.csv", preprocessed_data, delimiter=",") 
print x_train.shape
'''
test_split_x, test_split_y , train_split_x , train_split_y = train_test_split(x_train, y_train,0.2)
x_train = train_split_x
y_train = train_split_y
x_test = test_split_x
y_test = test_split_y

'''
# ======= L1 SVM Selected features========
from sklearn.svm import LinearSVC
print x_train.shape
X_new = LinearSVC(C=0.01, penalty="l1", dual=False).fit_transform(x_train, y_train)
x_train= X_new
print X_new.shape

test_split_x, test_split_y , train_split_x , train_split_y = train_test_split(x_train, y_train,0.2)
x_train = train_split_x
y_train = train_split_y
x_test = test_split_x
y_test = test_split_y



#============== SVM ==============
from sklearn.svm import SVC
from sklearn import metrics

clf = SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.001, kernel='linear', max_iter=-1, probability=True,
  random_state=None, shrinking=True, tol=0.001, verbose=False) 
print "\n\n============== SVM ==================="
Accuracy =0
Accu_cross=0
'''
for i in range(10):
    predicted = cross_validation.cross_val_predict(clf, x_train, y_train , cv=10)
    Accu_cross=cross_val_eval(predicted , y_train)
    #print Accu_cross
    scores = cross_val_score(clf, x_train, y_train , cv=10)
    score_mean=scores.mean()
    Accuracy = Accuracy + score_mean
    
print 'SVM Cross Validation Accuracy1: %f'% Accu_cross
#print 'SVM Cross Validation Accuracy2: %f'% np.around(Accuracy/10, decimals=3)
'''
clf.fit(x_train, y_train)
print "RF evaluation on seperate Train and Test dataset:"
Acuuracy1 = evaluate(clf, x_train, x_test, y_train,y_test,'SVM')
#print 'Accuracy on test data:%f'% Acuuracy1
#Accu_cross=0
'''
#============== Logistic ===================
from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(class_weight='auto')
Accuracy=0
print "\n\n============== Logistic Regression ==================="
for i in range(10):
    scores = cross_val_score(clf, x_train, y_train , cv=10)
    predicted = cross_validation.cross_val_predict(clf, x_train, y_train , cv=10)
    Accu_cross=cross_val_eval(predicted , y_train)
    score_mean=scores.mean()
    Accuracy = Accuracy + score_mean

print 'LR Cross Validation Accuracy: %f'%Accu_cross

clf.fit(x_train, y_train)
print "LR evaluation on seperate Train and Test dataset:"
#ypred = clf.predict(x_test)
#Accuracy= evaluate(clf, x_train, x_test, y_train, y_test, 'LR') ******
#print 'Accuracy on test data:%f'% Accuracy
Accuracy=0
Accu_cross=0

#============== Random Forest ===================
from sklearn.ensemble import  RandomForestClassifier
clf = RandomForestClassifier(n_estimators=10, max_depth=None,min_samples_split=1, random_state=0)
Accuracy=0
print "\n\n============== Random Forest ==============="
for i in range(10):
    scores = cross_val_score(clf, x_train, y_train , cv=10)
    predicted = cross_validation.cross_val_predict(clf, x_train, y_train , cv=10)
    Accu_cross=cross_val_eval(predicted , y_train)
    #print Accu_cross
    score_mean=scores.mean()
    Accuracy = Accuracy + score_mean
print 'RF Cross Validation Accuracy: %f'% Accu_cross

#clf.fit(x_train, y_train)
#print "RF evaluation on seperate Train and Test dataset:"
#ypred = clf.predict(x_test)
#Acuuracy =evaluate(clf, x_train, x_test, y_train, y_test, 'RF')
#print 'Accuracy on train data:%f'% Acuuracy2
#print 'Accuracy on test data:%f'% Acuuracy
Accu_cross=0

#============== kNN ===================
from sklearn.neighbors import KNeighborsClassifier
clf = KNeighborsClassifier(n_neighbors=10)
Accuracy=0
print "\n\n============== kNN ==================="
for i in range(10):
    scores = cross_val_score(clf, x_train, y_train , cv=10)
    score_mean=scores.mean()
    predicted = cross_validation.cross_val_predict(clf, x_train, y_train , cv=10)
    Accu_cross=cross_val_eval(predicted , y_train)
    Accuracy = Accuracy + score_mean
print 'KNN Cross Validation Accuracy: %f'%Accu_cross

clf.fit(x_train, y_train)
print "KNN evaluation on seperate Train and Test dataset:"
#Acuuracy =evaluate(clf, x_train, x_test, y_train, y_test, 'KNN')
#Acuuracy2 = evaluate(clf, x_train, x_train, y_train,y_train,'SVM')
#print 'Accuracy on train data:%f'% Acuuracy2
#print 'Accuracy on test data:%f'% Acuuracy
Accu_cross=0


#=============== Gradient Boosting Classifier ====================
from sklearn.ensemble import GradientBoostingClassifier
clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=300, subsample=1.0, min_samples_split=2, min_samples_leaf=1,max_depth=3, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False) 
for i in range(10):
    scores = cross_val_score(clf, x_train, y_train , cv=10)
    predicted = cross_validation.cross_val_predict(clf, x_train, y_train , cv=10)
    Accu_cross=cross_val_eval(predicted , y_train)
    score_mean=scores.mean()
    Accuracy = Accuracy + score_mean
print "\n\n========== Gradient Boosting Classifier ============"
print 'GB Cross Validation Accuracy: %f'%Accu_cross

#clf.fit(x_train, y_train)
#print "GB evaluation on seperate Train and Test dataset:"
#Acuuracy =evaluate(clf, x_train, x_test, y_train, y_test, 'GB')
#Acuuracy2 = evaluate(clf, x_train, x_train, y_train,y_train,'SVM')
#print 'Accuracy on train data:%f'% Acuuracy2
#print 'Accuracy on test data:%f'% Acuuracy
Accu_cross=0
Accuracy=0
#=============== Ada Boost Classifier ====================
from sklearn.ensemble import AdaBoostClassifier
clf = AdaBoostClassifier()
for i in range(10):
    scores = cross_val_score(clf, x_train, y_train , cv=10)
    predicted = cross_validation.cross_val_predict(clf, x_train, y_train , cv=10)
    Accu_cross=cross_val_eval(predicted , y_train)
    score_mean=scores.mean()
    Accuracy = Accuracy + score_mean
print "\n\n========== Ada Boost Classifier ============"
print 'AdaBoost Cross Validation Accuracy: %f'%Accu_cross

#clf.fit(x_train, y_train)
#print "ET evaluation on seperate Train and Test dataset:"
#Acuuracy =evaluate(clf, x_train, x_test, y_train, y_test, 'AdaBoost')
#Acuuracy2 = evaluate(clf, x_train, x_train, y_train,y_train,'SVM')
#print 'Accuracy on train data:%f'% Acuuracy2
#print 'Accuracy on test data:%f'% Acuuracy
Accu_cross=0
Accuracy=0

#=============== Decision Tree Classifier ====================
from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(max_depth=None, min_samples_split=10,random_state=0)
print "\n\n========== Decision Tree Classifier  ============"
for i in range(10):
    scores = cross_val_score(clf, x_train, y_train , cv=10)
    predicted = cross_validation.cross_val_predict(clf, x_train, y_train , cv=10)
    Accu_cross=cross_val_eval(predicted , y_train)
    score_mean=scores.mean()
    Accuracy = Accuracy + score_mean
print 'DT Cross Validation Accuracy:%f'%Accu_cross

print " DT evaluation on seperate Train and Test dataset:"
clf.fit(x_train, y_train)
Acuuracy =evaluate(clf, x_train, x_test, y_train, y_test, 'DecisionTree')
#Acuuracy2 = evaluate(clf, x_train, x_train, y_train,y_train,'SVM')
#print 'Accuracy on train data:%f'% Acuuracy2
print 'Accuracy on test data:%f'% Acuuracy

#plt.show()
'''
